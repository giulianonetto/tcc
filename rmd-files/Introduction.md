---
title: "Introduction"
bibliography: config/library.bib
csl: config/abnt-ufrgs-initials.csl
header-includes:
   - \usepackage{longtable}
output: 
  word_document:
    reference_docx: config/template.docx
    keep_md: true
---



  Idiopathic Pulmonary Fibrosis (IPF) is a chronic, progressive, irreversible lung disease. After diagnosis, the interstitial condition commonly presents 3-5 years of life expectancy if untreated [@Wolters2018]. Alveolar damage is characterized by dilatation of the bronchi, tissue remodeling and parenchymal fibrosis which seriously impair gas exchange. The first time the current name was used it referred to radiography tests suggestive of pulmonary fibrosis of unknown etiology, although the disease had been recognized over one hundred years before - named cirrhosis of the lung at the time [@Robbins1948, @Wolters2018]. Over three decades after the nomenclature was first published, in 1976 it gained widespread use after a review article [@Wolters2018].
  
  Currently, radiographic and histopathological patterns of usual interstitial pneumonia (UIP) with apparently no secondary causes form the basis for IPF definition [@Richeldi2017]. The disease presents sporadic and familial forms. From the edges of the lungs - base and periphery -, it spreads all over the pulmonary tissue causing dry cough, fatigue and dyspnea. The latter is nearly universal in the history of IPF patients and may progress over a period of years, while the first two may be absent in the early stages. Universal findings also include low diffusion capacity of the lung for carbon monoxide (DLCO) and Bilateral Velcro-like crackles. The chest radiograph may present nonspecific changes or bilateral basal reticular abnormalities [@Lederer2018]. The difficulty of the diagnosis is illustrated by the fact that clinicians often mistake the presence of dyspnea as indicator of heart failure or chronic obstructive pulmonary disease (COPD), failing to consider interstitial lung disease, which delays IPF detection significantly.
  
  Although its cause is not clear, there is currently a recognized increase in IPF prevalence worldwide [@Wolters2018]. As a disease of aging, this may be due to population increasing phenomena, but also to recent improvements in disease recognition [@Lederer2018]. Unusual before the 50 years of age, IPF prevalence almost doubles for every decade of life thereafter [@Wolters2018]. In North America and Europe, the incidence of IPF ranges from 3 to 9 cases per 100000 person-years, while South America and East Asia show less than 4 cases per 100000 person-years [@Hutchinson2015]. Assuming these numbers as conservative, a recent Brazilian study tried to calculate more precise estimates for the local reality. Using data from the 2010 Brazilian National Census and rates reported by previous studies, the authors suggested annual incidence of IPF between 6.841 and 9.997 cases per 100000 people, whereas the prevalence was estimated at a range of 13.9-18.3 cases per 100000 people [@Baddini-Martinez2015]. In terms of mortality, another study estimated 1.2 deaths per 100000 people in 2010, although this is certainly an underestimation as the authors limited their analysis to data from the Information Technology Department of the Brazilian Unified Health Care System (DATASUS), which does not reflect private medicine practices [@Rufino2013]. It is clear, however, that Brazil's data does not oppose the world tendency of IPF prevalence increase.
  
  The number of disease cases has risen along with the number of identified risk factors. Regarding hospitalization, over three quarters of the cases are due to respiratory events, with acute exacerbations as the main cause [@Brown2015; @Song2011]. In-hospital mortality rate has been reported to reach 50 %, with five-year survival from initial diagnosis lower than 20 % [@Song2011]. In such a complex scenario, multidimensional indexes that include sex, age and physiological abnormalities may be useful to predict mortality [@Richeldi2017]. Risk factors also include environmental exposures to dust and air pollution, smoking, chronic viral infections ( _e.g._ Epstein–Barr virus, cytomegalovirus and Kaposi sarcoma-associated herpesvirus) and other comorbidities. Of note, one third of inherent individual risk of IPF have been attributed to genetic variants. Mutations in genes associated with telomere length - such as TERT, TERC, PARN, and RTEL1 - are related to higher higher risk of IPF. The same holds true for genes responsible for cell adhesion, integrity, and mechanotransduction ( _e.g._ DSP, AKAP13, CTNNA, and DPP9) [@Lederer2018].
  
  Mucin 5B overexpression in small-airway epithelial cells is a universal finding in patients with IPF, which has led to the hypothesis that impaired mucociliary clearance may be linked to changes in microbiome and innate immune responses that promote IPF [@Molyneaux2017; @Lederer2018]. Although the gene expression pattern appears to be genotype-independent, single-nucleotide polymorphisms in the MUC5B gene are notable risk factors for IPF, even though - paradoxically - they may also predict slower disease progression [@Peljto2015]. Host-microbiome interactions are also highlighted by the central role of macrophages in lung fibrosis development along with the finding that IPF risk is also increased by mutations in the TOLLIP gene, which encodes a protein associated with toll-like receptor family pathways [@Lederer2018]. Lung of patients typically present higher bacterial loads, differences in microbiota composition and diversity, and even increases in potentially pathogenic bacteria ( _e.g._ _Staphylococcus_ spp. and _Streptococcus_ spp.). Finally, epigenetic reprogramming has been associated with pathogenesis of IPF [@Richeldi2017]. Upregulation of lung development genes, trans-regulatory methylation marks near transcription factors, and potentially pathogenic modifications in miRNAs have been pointed as complex reprogramming processes often associated with pro-fibrotic pathways. 
  
  Overall, it is well accepted that IPF arises from recurrent, subclinical epithelial injury, especially in genetically-predisposed individuals with accelerated epithelial aging [@Lederer2018]. In such patients, the repetitive alveolar damage can induce pro-fibrotic epigenetic reprogramming, persistent cell senescence, production of pro-fibrotic molecules as well as activation of mesenchymal cells [@Richeldi2017]. Recent studies, however, have been suggesting that the trigger for lung fibrosis might not be strictly related to exogenous aggression, which is yet to be further investigated [@Kulkarni2016; @Naikawadi2016]. Still, altered migration, proliferation and mixed activation profiles of epithelial cells, especially alveolar epithelial type 2 cells, are a hallmark of IPF [@Richeldi2017]. These and other pathological discoveries will be critical for early diagnosis and treatment development.
  
  Currently, diagnosis of IPF is mainly focused on high-resolution computed tomographic (CT) imaging after identification of history and physical examination that are suggestive of interstitial lung disease [@Lederer2018]. Once the suspicion is confirmed, further physical examination is performed to rule out related disorders such as chronic hypersensitivity pneumonitis and connective-tissue disease, as well as autoimmune conditions. Antinuclear antibodies, rheumatoid factor, antibodies against cyclic citrullinated peptides, Scl-70, Ro, La, U1-RNP, Jo-1 and other immunological tests comprise the serological examination routine, even though the presence of these biomarkers may not be enough to confirm IPF absence [@Lederer2018]. Often, lung biopsy is not performed in face of usual interstitial pneumonia (UIP) in high-resolution CT associated with suitable history, these being enough for IPF diagnosis. However, obvious CT patterns are not always present and invasive methodologies are needed. If histologic UIP is present, IPF diagnosis is confirmed. Otherwise, multidisciplinary discussions are encouraged as means of increasing diagnostics and prognosis assessment [@Lederer2018].
  
  Finally, in terms of pharmacotherapy, IPF management has been through recent international standardization. In 2015 the American Thoracic Society, European Respiratory Society, Japanese Respiratory Society and Latin American Thoracic Association (ATS/ERS/JRS/ALAT) released international IPF therapy guidelines, updating a previous version from 2011 [@Raghu2015]. The guidelines strongly favored the recommendation for use of Pirfenidone and Nintedanib [@Richeldi2017]. While the latter is a tyrosine kinase inhibitor taken twice daily, the former acts on various pathways, inhibiting TGF-b production and downstream signaling, among other effects [@Lederer2018]. In addition to the need of three daily doses, Pirfenidone may cause anorexia, nausea and photosensivity, and may have its blood levels increased by CYP 1A2 inhibitors. Nintedanib causes diarrhea, risk of bleeding and arterial thrombosis, and a low risk of gastrointestinal perforation. Both treatments require liver-function monitoring and have similar efficacy profiles - reducing forced vital capacity decline rate by nearly half, clearly insufficient for stopping disease progression. 
  
# IPF Immunological background

  Despite the limited capacity of recapitulating IPF, animal models have been useful for identifying related pathways relevant for drug discovery and diagnostic tools development. Using these techniques, several immune-related molecules have been implicated to IPF, including transforming growth factor beta (TGF-b), connective-tissue growth factor (CTGF), tumor necrosis factor (TNF), fibroblast growth factor 2, platelet-derived growth factor, several matrix metalloproteinases and chemokines [@Lederer2018; @Richeldi2017]. The fibrotic process itself has its own singularities as well. A wide range of interleukins and other immunologically active mediators have been proposed as critical for fibrotic processes. Among others, these include IL-33, IL-17A, IL-25, TSLP, and IL-13 [@Gurczynski2017; Li2014; @Camelo2017; @Hams2015]. Regarding immune cell populations, macrophages have been shown to play central roles in pulmonary fibrosis and the elucidation of their biological dynamics is an active area of current research effort [@Venosa2016; @Lee2018; @Kurowska-Stolarska2009; @Misharin2013; @Wynn2010; @Misharin2017].
  
  Subpopulations of macrophages and monocytes-derived cells are recognized as centrally active in pulmonary immunological processes [@Martinez2014; @Syrbu1996; @Braga2015; @Misharin2013; @Hussell2014]. Indeed, these cells can be source of pathophysiological information throughout disease progression for two main reasons. Firstly, they act as sentinels for foreign aggression, which assures detectable variance in animal models from the very beginning of the induced lesion and inflammation [@Martinez2014]. Secondly, as anti-inflammatory and pro-fibrotic mechanisms progress, the above-mentioned cells are also fundamentally involved in both the regulatory functions and the fibrosis promotion [@Luzina2015; @Camelo2017]. Most recruited monocytes differentiate into macrophages upon tissue arrival. These cells respond differently across distinct phases of pulmonary immunological activity so that understanding their dynamics throughout the course of lung aggression is critical [@Wynn2010]. Although not limited to a dichotomous model, M1- and M2-like cells typically promote and modulate these mechanisms, and their deep phenotypic profiling is crucial for the understanding of IPF and other fibrosis-related conditions.
  
## Macrophages and fibrosis development
  
  The definition of common macrophage subpopulations is currently under scientific scrutiny and revision [@Martinez2014]. Traditionally, macrophages were thought to be divisible into two groups, depending on the activation stimuli to which they are exposed [@Abbas2017]. Classical activation is triggered by exposure to microbial toll-like receptor ligands such as lipopolysaccharide (LPS) and cytokines commonly released by T helper 1 cells (TH1), especially Interferon-g (IFN-g). These signals enhance the antimicrobial and tumoricidal properties of what is then named M1 macrophage. M1 cells promote potentially harmful inflammation, but are crucial to fight, for instance, viral infections and cancer [@Alfano2013; @Dale2013; @Ginhoux2016]. Alternative activation occurs when macrophages are exposed to cytokines characteristic of T helper 2 cells (TH2), notably IL-4 and IL-13, and the then called M2 macrophages inhibit inflammation and promote tissue repair and fibrosis [@Delves2017]. The M1 vs M2 paradigm has been used worldwide and certainly contributed to the advancement of modern immunology. The M1 or M2 responses were referred to as analogous to the TH1 and TH2 responses, and the preferential differentiation of a group of cells in a given environment into one of the phenotypes is termed as "macrophage polarization" [@Ginhoux2016]. 
  
  However, as these cellular subtypes were first defined with controlled _in vitro_ experiments, more complex phenotypic experimental characterizations started to give birth to the model questioning. Subdivisions of M2 macrophages arose from the observation of subtly distinct phenotypes, depending on the anti-inflammatory stimulus used. M2a phenotype is traditionally triggered by IL-4 and IL-13; M2b phenotype is induced by IL-10 exposure; and M2c cells are generated with a combination of immune complexes and LPS. Flow cytometry analyses now include several markers for each phenotype and their subdivisions, but these are often conflicting between studies [@Tarique2015; @Venosa2016; @Misharin2013]. It is now clear that many homeostatic and pathological situations do not support M1 or M2 phenotypes dichotomy, and that in many cases these cells present high phenotypic plasticity [@Ginhoux2016]. Macrophage activation is influenced by their ontogeny ( _i.e._ if they derive from yolk sac, as the microglia, fetal liver monocytes, as lung macrophages and Kupffer cells, from both, as Langerhans cells, or if they are replaced with adult bone marrow monocytes, as in the gut, heart an dermal macrophages). Tissue-specific signals also drive macrophage activation both in homeostasis and disease and, importantly, the same stress signals with the same kinetics result in differentially programmed macrophages if these have been exposed to different microenvironments or previous stimuli. Taken together, these recent advances lead the understanding of macrophage biology to a multidimensional model of activation, with major microenvironment particularities and transcriptional programs significantly variable across human and mouse normal tissues and pathological conditions.  
  
  Faced with the need for standardization, a group of macrophage biology researchers suggested a reviewed nomenclature and experimental guidelines for subpopulation studies [@Murray2014]. The proposal was based on three principles: "source of macrophages, definition of the activators, and a consensus collection of markers to describe macrophage activation". As it remains a challenge to define macrophage phenotypes that describe accurately the cellular function across time and environmental conditions, the authors proposed nomenclature designation based on the stimuli to which the cells are exposed, for _in vitro_ studies. For instance, traditional M1 macrophages would now be named M(LPS) or M(IFN-g) cells, while M2 would be further divided into M(IL-4), M(IL-4+IL-13), M(IL-10), etc. For _in vivo_ studies, the cell names would explicitly declare their multiple markers rather then forcing a fit into M1 or M2 spectra. Many confusions are avoided by this approach. For instance, the expression of Arginase-1 has been used to describe M2 - or M(IL-4) - macrophages, while it is well known that the enzyme is also expressed by M1 spectrum cells as well as resident macrophages [@Murray2014]. Additionally, the authors suggest terms to be avoided as these may further confuse classification: "regulatory macrophages" has been used to refer to M2-like cells, despite the fact that all macrophages show regulatory functionalities at some point and even within the M2 spectrum the regulatory functions are considerably heterogeneous. Although their nomenclature standards have been extensively encouraged, macrophages are still presented as M1-like or M2-like in many occasions, especially when accurate classification is not achieved [@Italiani2014; @Venosa2016; @Malaviya2016; @Becker2015a; @Wermuth2015; @Murray2017]. In such a controversial scenario, novel approaches are currently needed to further improve macrophage classification.
  
## Novel approaches in macrophage biology research
  
  One of the promising techniques applied to macrophage study is high-throughput gene expression analysis. High-throughput technologies have been available for almost two decades now, and these have deeply challenged our current understanding of macrophage biology [@Stables2011; @Kidd2014; @Pevsner2015]. A remarkable work from Xue and colleagues (2014) is an outstanding example of these advances. Using diverse _in vitro_ stimuli, the authors performed single-cell RNA sequencing on almost 300 macrophages [@Xue2014]. Weighted Correlation Network Analysis identified 49 stimulus-specific gene modules that could be used as gene sets for enrichment assessment on data from patients and animal models. This approach deeply extended M1- versus M2-paradigm towards a "spectrum model of human macrophage activation" and was able to identify a refined, activation-independent core signature for human and murine macrophages. In fact, module analysis has been widely used to investigate transcriptional profiles of immunological processes. First designed using k-means clustering algorithm for microarray data, it identifies groups of genes that are coordinately expressed in a given dataset while supporting systems-scale analysis for translational research [@Chaussabel2008]. Currently, this type of procedure is performed by widely used software which implement diverse set of machine learning algorithms [@Langfelder2008]. Additionally, it has been adapted to RNA sequencing and single-cell RNA sequencing data. The wide range of algorithms currently used has been comprehensively reviewed elsewhere [@Saelens2018].
  
  Apart from transcriptome studies, proteomic data analysis has yielded promising results as well [@Court2017]. Despite the difficulty of validating direct relationships between gene and protein expression patterns, the one agreement is that M1 versus M2 model is not enough to explain macrophage polarization repertoire [@Martinez2014; @Tarasova2016a; @Kamal2018]. Nevertheless, as Next Generation Sequencing became broadly available at relatively low costs, proteome research is still to match high-throughput transcriptomic techniques in terms of scaling and data generation capacity. Overall, multi-omics approaches start to gradually emerge as the amount of data currently being generated by far exceeds the data analysis resources available for the scientific community.
  
# Bioinformatics and Functional Genomics
  
  According to Jonathan Pevsner (2015), "functional genomics is the genome-wide study of the function of the DNA (including genes and nongenic elements) as well as the nucleic acid and protein products encoded by DNA" [@Pevsner2015]. The author also states that functional genomics relies primarily on the use of high-throughput technologies, such as Next Generation Sequencing (NGS) and microarray. More traditional techniques such as real-time polymerase chain reaction are used as means of validation. Finally, Pevsner emphasizes that functional genomics plays a fundamental role in solving one of the ultimate problems in modern biology: understanding the relationship between genotype and phenotype [@Pevsner2015]. 
  
  It is not surprising that these approaches have been broadly applied to macrophage biology studies [@Fonseca2017]. The massive amount of data generated, though, represents a challenge for researchers. This scenario has led to the advance of the bioinformatics field, which stands at the interface between molecular biology and computer science. Briefly, bioinformatics seeks the analysis of molecular sequences - which can derive from DNA, RNA, or proteins - to answer a broad range of biological questions. Genomics is dedicated to the analysis of DNA sequences of organisms - the genomes -, while transcriptomics analyzes the transcriptome and proteomics, the proteome - and so forth. Going further, Functional Genomics takes advantage of genome-wide assays to understand gene, transcript, and protein functions. Although there are obvious overlaps among the terms, a first perspective of the big picture of bioinformatics suggested by Pevsner is the cell itself: the central dogma of molecular biology states that the relationships between DNA, RNA and proteins ultimately generate cellular phenotype. In genomics, the central dogma is translated into the relationships between the genome, transcriptome and proteome. This approach greatly enhances the complexity of cellular phenotype modeling, and hence computational methods are needed [@Pevsner2015]. Still, strict definition of these and related terms is often controversial and beyond the scope of this work.
  
## Bioinformatics Development
  
  The development of bioinformatics software is probably one of the most exciting areas of recent scientific advances. A popular approach is web-development for scientific computing. Open, web-available tools such as Basic Local Alignment Search Tool (BLAST) at National Center for Biotechnology Information (NCBI) make it possible for researchers with no programming experience to perform complex bioinformatics analyses [@Quereda2016]. The paper that introduced BLAST in 1990 counts over 74000 citations as of November, 2018 - similar to the citation numbers from Cesar Victoria, one of the Brazilian scientists with the highest citation counts at Google Scholar currently [@Victoria2018]. However, programming abilities are a restrictive must for those seeking to further customize their analyses or to develop their own algorithms. Although several academic majors take advantage of bioinformatics development, from biology to health sciences, programming skills are often neglected. In Brazil, few are the undergraduate programs that include bioinformatics as a discipline and even fewer are the specialized and well developed bioinformatics graduate programs. This reality is now trending to change as computational biology applications gain major highlights in media and academic routine.
  
  Regarding programming languages, one is particularly outstanding in the field of Functional Genomics. The R programming language is both a language and an environment for statistical computing and graphics, similar to the S language previously developed by John Chambers and colleagues at Bell Laboratories [@Rproject2018]. Like S, in R one can program their own functions and extend base functionality through the use of packages - which are just R code with certain functionalities validated and encapsulated. Also, it is possible to link C and C++ code to these packages so that computationally-intensive tasks can be performed. The idea of programming "environment" comes from the production a coherent and well-planned framework in which statistical computing can be run and developed. This can contrast with other programming languages such as python, which can be applied to statistics and data analysis in spite of its broader range of applications. Python is another very popular data science language with extensive machine learning algorithm development, although its reach in the field of functional genomics may not be as extensive as in the case of R.
  
  The success of R within bioinformatics field has a particular reason. In 2001, a group of researchers, bioinformaticians, statisticians, and data scientists released Bioconductor, an open-source, open development software project dedicated to the analysis of high-throughput genomic data [@Gentleman2004]. To date, the package repository contains over 1600 software packages, which undergo continuous automated testing in addition to formal initial review [@Huber2015]. Bioconductor also supports the rapid development of standard workflows combining highly complex data structures and statistical inference tools, regression, network analysis, machine learning and data visualization, which is especially important for reproducible research. It is deeply documented at three levels: whole workflows combining multiple tools, packages vignettes providing the narrative for the package usage with code and data analysis examples, and manual pages that serve as reference for detailed descriptions of all inputs and outputs for the packages functions. With enough experience, users can become developers and share their work with others through the repository. The choice of R language is justified by its high-level statistical and graphical utilities, which yields rapid prototyping creativity, flexibility and reproducibility unmatched by web-based tools software and general-purpose languages [@Huber2015]. The whole Bioconductor structure and development culture are focused on reproducible research and data analysis, which translate into good practices for documentation and software development that well enforced by the users and developers community.
  
## Microarray data analysis using Bioconductor

  DNA Microarray is a genome-wide gene expression measurement technique that emerged by 2000, although it was first developed in the previous decade at Stanford University and National Institute of Health (NIH) [@Pevsner2015]. It has been one of the most widely used tool for genomic studies worldwide [@Sinha2014]. On the surface of a solid support, several nanograms of DNA are immobilized in a grid-like array. The RNA extracted from biological samples is usually converted to complementary DNA (cDNA) - or cRNA, depending on the platform -, labeled with fluorescence, and selectively hybridized to the array. Each transcript should have a corresponding nucleic acid molecule to which hybridize, although often more than one probe maps to the same gene. Either for technical reasons, or because a particular gene may have more undergo alternative splicing and thus different expression values are expected, _probesets_ are particularly common on the Affymetrix platform [@Liu2003]. Once the microarray is washed, image analysis quantifies the fluorescence signals, and the spot intensities are assumed to correlate with the initial quantity of sample mRNA. The amount of starting material varies across technologies, but for many cases about 1-3 ug (micrograms) of total RNA is needed and the yielded hybridization material usually consists of 5 ng of cDNA. 
  
  Data analysis seeks the identification of differentially expressed genes and broad patterns of gen expression [@Pevsner2015]. The Minimum Information About a Microarray Experiment (MIAME) provides good practices for experiment description, including experimental and microarray design, sample preparation, hybridization procedures, image analysis, and normalization controls. Microarray data is public available mainly through ArrayExpress and Gene Expression Omnibus from the European Bioinformatics Institute (EBI )and NCBI, respectively. Following MIAME is a requirement for using these databases to share your own data. Once microarray data is acquired, it must be properly normalized, undergo inferential statistics ( _e.g._ t-tests, analysis of variance), exploratory analysis ( _e.g._ unsupervised learning as clustering, dimensionality reduction), and classification ( _e.g._ supervised analyses as linear discriminants, support vector machines). These procedures ultimately lead to biological confirmation, which may be performed by non-high-throughput technologies such a RT-PCR. As all steps require complex calculations and extensive computing, many software options are available at Bioconductor, including platform-specific workflows and high-dimensional statistics tools.
  
  Microarray data distribution is often non-parametric and thus data normalization is essential for sample and experiment comparisons [@Quackenbush2002]. This is because of differences in the labeling efficiency, the amount of starting material, cDNA quality, signal detection, and so forth. Many techniques have been developed to solve this issue. Variance Stabilization and Normalization (VSN) assumes the variance for a specific probe mainly depends on its mean expression level and uses a linear transformation procedure to keep variance approximately constant [@Huber2002]. Such a technique is broadly applied and is implemented in R through the vsn package - available from Bioconductor.
  
  In 2003, Rafael Irizarry introduced the Robust Multiarray Analysis as a method of background correction, quantile normalization, and probeset summarization of probe intensities from Affymetrix platform raw data [@Irizarry2003]. As a non-parametric approach, quantile normalization makes no assumptions on the expression distributions. For each array, each probe expression measurement is assigned to a quantile. Normalization results from converting original probeset values to their corresponding quantile values. Using a convolution model, RMA is able to distinguish true probeset signal from noise. A improved version, GCRMA, increases RMA's accuracy by adjusting nonspecific hybridization using sequence information [@Pevsner2015]. After comparing over 30 algorithms for Affymetrix microarray data, Irizarry and colleagues demonstrated the leading capacity of RMA and GCRMA procedures [@Irizarry2006]. Both methods can be easily applied through the affy package [@Gautier2004].
  
  Another issue with high-throughput data analysis is the amount of statistical tests. When measuring differential gene expression, one may perform over 20000 t-tests or Mann-Whitney and Wilcoxon tests, for instance - one for each probeset or gene. In this scenario, with a p-value threshold of 0.05, one can expect around 1000 false-positive rejections of the null hypothesis - an unacceptably high rate of type I error. In order to control for these, one must consider correction of p-values.
  
  The Bonferroni procedure is used to control the Family Wide Error Rate, which can be defined as the probability of making at least one type I error among all tests [@Irizarry2015]. It is considered a rather conservative correction as it sets a new significance cutoff by dividing our previous one - 0.05 - by the number of statistical tests performed. Thus, one must not expect high statistical power with a resulting $\alpha {= 0.0000025}$. A more common approach is to control the False Discovery Rate, which is the proportion of false calls among one's positive results  - amount of errors over the number of rejections of the null. In gene expression experiments, $FDR {= 0.05}$ means that 5% of transcripts that were called significant are actually not differentially expressed [@Pevsner2015]. For a dataset with 20000 genes and 100 significantly induced or repressed genes, such an FDR value would yield only 5 type I errors. The Benjamini-Hochberg procedure, easily applied in R, ranks p-values and assures an FDR below a given value of the analyst choice - typically 0.05 [@Irizarry2015].
  
  A final microarray data analysis deserves consideration regarding the detection of differentially expressed genes. In R, this task is commonly performed using linear models. The most common Bioconductor package for this purpose is limma [@Ritchie2015]. It computes ordinary t-statistics for linear model fits to all genes and then uses Bayesian modeling to moderate residual variance. As limma has been available for almost two decades now, novel packages became publicly available trying to extend and improve limma capabilities. Alternative approaches emerged for time-course gene expression analysis as it is particularly complex. MaSigPro is another R package which uses two regression steps for this specific scenario. First, it fits a global regression model - typically polynomial - and, secondly, it performs step-wise regression to observe group differences and statistically significant longitudinal profiles of gene expression [@Conesa2006]. Finally, longitudinal gene set analysis software has been developed by Hejblum and colleagues [@Hejblum2015]. The TcGSA package, available from the Comprehensive R Archive Network (CRAN), extends limma and MaSigPro techniques through random effects modeling with maximum likelihood estimates. It is capable of handling unbalanced repeated measures of gene expression and takes into account potential heterogeneity of expression profile within gene sets. The identification of differences in longitudinal expression patterns across factors of interest is thereby made possible.
  
## RNA sequencing data analysis

  RNA sequencing (RNA-seq) is the implementations of Next Generation Sequencing applied to RNA expression analysis [@Pevsner2015]. Initially, isolation of fragmented messenger RNA and acquisition of cDNA are performed. The experimental procedures vary depending on the platform and on the experiment objectives ( _i.e._ qualitative or quantitative), but they often involve target enrichment, which consists of removal of ribosomal RNA and selecting 3'-end transcripts with long poly-A tails. Once the double-stranded cDNA library is prepared along with platform-specific adaptor sequences, the DNA can be amplified for subsequent sequencing. Many platforms are available, and they vary largely in terms of sequencing chemistry, base-call quality, read length, and many strengths and weakness that need to assessed based on the experiment objectives [@Metzker2010]. Of note, read lengths for RNA-seq experiments are often around 50 base pairs (single-end), although  novel transcriptome assembly and annotation projects may benefit from paired-end sequencing with larger reads [@Chhangawala2015].
  
  Bioconductor offers many pipelines for RNA-seq data, which differs from microarray mainly because the common linear models - based on Gaussian distribution - fail to accurately describe data structure. This is due the fact that NGS technologies yield data in the form of read counts ( _i.e_ positive integers, as opposed to fully continuous variables) and these tend to better fit into Poisson or negative binomial distributions [@Anders2010]. Recently, Costa-Silva and colleagues assessed several available software tools for RNA-seq analysis [@Costa-Silva2017]. Using quantitative RT-PCR as reference, the authors concluded that read mapping, a crucial step in data preprocessing, is satisfactorily performed by all software evaluated. Regarding modeling for statistical detection of differentially expressed genes, the best-performing options were limma+voom [@Law2014], NOIseq [@Tarazona2015], and DESeq2 [@Love2014].
  
  Limma, which stands for Linear Models for Microarray Data, was not originally developed for RNA-seq data. However, the so-called voom method is able to generate precision weights for each observation by estimating mean-variance relationships of log-counts. When entering these into Bayesian modeling pipeline, microarray-derived analytical tools become as accurate as count-based analysis methods - most common strategy for RNA-seq [@Law2014]. For this reason, one may perform both microarray and RNA-seq data analysis using the same Bioconductor-availabe limma package. 
  
  Another Bioconductor package, NOISeq, combines non-parametric methodology with empirical Bayes modeling to build its NOISeqBIO pipeline [@Tarazona2015]. It estimates a statistic Z whose distribution is a mixture of those from (1) invariant genes, and (2) genes whose expression changes between conditions. Given a z score for a particular gene, the probability of differential expression can then be calculated using Bayes Rule.
  
  Finally, DESeq2 extends its previous version (DESeq) by first fitting a generalized linear model for each gene in an expression matrix - assuming negative binomial distribution (or gamma-Poisson distribution) [@Love2014]. The mean parameter is correcter by a scaled normalization factor, which accounts for sources of technical biases, including GC content differences, gene length, and sequencing depth between samples. The model uses a logarithmic link so that, in the simplest instance of control versus treatment experiment, it returns coefficients that indicate the gene's overall expression strength plus its fold change between the conditions as binary logarithm (log2 Fold Change). Next, DESeq2 uses shared variance information across genes while assuming similar dispersion for genes with similar average expression strength. It shrinks gene-wise dispersions towards a predicted value based on expression strength similarities - a process that is weighted using Bayes approach. A similar shrinkage method is used to correct log2 fold changes thereby removing overestimation of expression changes for low read counts. According to the work from Costa-Silva and colleagues, DESeq2 pipeline yields 93% of specificity and 84% of true positive rate, thus being the top-performing method among those included in the study [@Costa-Silva2017].
  


# Defining Macrophage Gene Signatures

## Macrophage Genomic Integrative Analysis

  Genomic integrative analysis is a computationally-expensive and rather complex task. First, one must integrate different technologies (_e.g._ microarray and RNA sequencing) from several distinct platforms (_e.g._ Affymetrix, Illumina, Agilent) [@Walsh2015]. Second, although greater number of samples yields higher statistical power, potential confounding factors must be taken into account. When it comes to lung injury, a wide range of animal models and human conditions have already been tested, and their respective datasets should be treated with care. For instance, the widely used bleomycin-induced IPF model shows enrichment of traditionally M1-associated genes at very early stages [@Bauer2015]. Fungal infection models, on the other hand, show divergent genomic markers with potentially protective roles associated with genes from the M2 spectrum [@Bhatia2011; @Margalit2015]. Both cases, though, may lead to pulmonary fibrosis through macrophage activity [@Iwasaki2016; @Gieseck2017; @Wynn2016]. Other challenges include the adequacy of sample sizes, pre-processing techniques, statistical analysis, modeling validation, experimental design as well as the lack of a comprehensive framework for the execution of genomic meta-analyses [@Ramasamy2008]. Of note, the term "meta-analysis" refers to cases when the researcher analyzes each dataset separately and draws conclusions based on the combination of final statistical results, whereas "cross-platform normalization" is used to describe the integration of raw data ("merging") from multiple sources for combined downstream analysis [@Walsh2015]. Here, we use "integrative analysis" to denote both terms interchangeably as not all datasets analyzed are suitable for merging.
  
  The applicability of integrative analysis for elucidating reproducible macrophage dynamics and even predicting clinical outcome based on the enrichment of their gene signatures has been previously tested [@Becker2015a]. Using data from human-derived macrophages challenged with two sets of _in-vitro_ activation stimuli, namely "classical" (IFN-g + LPS; TNF-a) and "alternative" (IL-4; IL-13), the authors were able to establish prognostic values in diverse clinical settings such as viral infections and asthma. Noteworthy, however, is the fact that gene signatures were still relatively limited by the M1 versus M2 paradigm, which hinders interpretation at the cellular and molecular levels. After all, how to understand the heterogeneity within such microenvironments and, furthermore, how to address similar macrophage subsets that are constantly overlooked (or that are yet to be described)? How comprehensive should an integrated analysis be to assure robustness of detected gene expression patterns? The answers to these questions may eventually lead to better pharmacology development and health care regarding many life-threatening, macrophage-related diseases.
  
  Recently, an elegant work integrated several datasets from human biopsies as well as data from wide range of mouse strains within the context of LPS exposure [@Buscher2017]. Surprising was not the high level of gene expression variability across strains, but the ability to nevertheless infer the degree of polarization of macrophages in transcriptome samples. To do so, the authors looked at the expression levels of IL-12b and arginase-1, known as M1- and M2-markers, respectively. After correction by population expression mean, the quotient between the two molecules' RMA (robust multi-array average: quantile normalized, background-corrected, log2 transformed intensities) represented what was named Polarization Factor Ratio (PFR). Next, the authors identified gene sets that were highly correlated with the PFR measurements. Those gene sets could then be used to describe the activation state of tumor-associated macrophages in cancer biopsy samples and even predict patient survival.
  
  Buscher's paper (2017) is an example of successful integrative analysis applied to the molecular study of macrophage biology. When it comes to IPF, their findings are further supported by protein-level assessment approaches as the behavior of immune cells in such conditions has been extensively studied [@Misharin2013a; @Yu2016; Mittar2011; @Landi2014]. Venosa and colleagues (2016) characterized the macrophage subpopulations in BAL fluid from Wistar rats exposed to nitrogen mustard (NM) – Figure 1 [@Venosa2016]. In their study, infiltrating M1-like macrophages rapidly increased until three days after the treatment, which correlated with the upregulation of proinflammatory M1 genes and tissue injury. The infiltrating M1 cells started being replaced after the third day, and an accumulation of M2-like macrophages was seen by the 7th day after NM exposure. A persistent increase of M2-like cells was observed until the 28th day after NM, and that response was correlated with M2 genes upregulation and fibrosis development. Figure 1 shows the time-course profile of such cells.
  
![Figure 1 - Macrophage dynamics in IPF model. Adapted from: [@Venosa2016].](Development_files/figure-docx/venosa-2.png)
  
  Many other studies confirm Venosa's data [@Wynn2016; @Gieseck2017; @Nie2017; @Luzina2015; @Peng2013; @Bauer2015; @Hams2015; @Braga2015; @Malaviya2016; @Kolahian2016; @Williamson2014; @Lee2018]. However, one may note the repetitive assumptions over the M1 versus M2 paradigm for most of the past works. High-throughput technologies combined with single-cell techniques are constantly being applied to yield more precise and informative data. Such a promising methodology has already revealed molecular heterogeneity much greater than previously predicted - for both innate and adaptive immune responses [@Lu2015; @Chevrier2017; @Neu2017]. As an example, mature T helper 17 (Th17) cells have been demonstrated to develop a wide range of transcription programs, which opposed previous conceptions of high gene expression similarity among antigen-specific T cells [@Han2014]. The ability to understand the development of these transcription diversities within populations once thought as homogeneous is one of the current challenges in biology and health research. Furthermore, we are still to meet comprehensive and reproducible proteomic characterization of macrophage subpopulations, although relevant advances have been made [@Court2017; @Tarasova2016; @Chevrier2017; @Becker2012]. Multi-omic integrative characterizations will therefore build a stronger and more robust body of knowledge to drive macrophage-based therapy and diagnostics [@Bakker2018].
  
  Here, we seek to determine a vast set of protein-coding genomic signatures that allows the investigation of possibly unacknowledged macrophage activation patterns across multiple datasets of pulmonary fibrosis models and IPF patients. In order to do so, we take advantage of single-cell sequencing data from human macrophages that were artificially stimulated with common and uncommon sets of signaling molecules so that we reach greater depth in our cross-platform characterization of macrophage dynamics [@Xue2014].

## Macrophage Gene Signatures

  Macrophages have been demonstrated to develop highly complex activation profiles in a diverse set of microenvironments [@Ginhoux2016]. As previously discussed, these cells are key players in conditions as idiopathic pulmonary fibrosis (IPF) [@Bauer2015; @Wynn2011; @Venosa2016]. Although many genetic markers are known to play important roles within the macrophage biology context, defining a robust set of gene signatures for the currently known phenotypic subsets remains a challenging task [@Martinez2014]. Recent cytometric and genomic approaches have revealed major limitations regarding the classic M1- versus M2-polarization model, which is no longer suitable to explain the biological dynamics of macrophage response [@Martinez2014].
  
  In the pursuit of standardization towards reproducible research, back in 2014 a group of specialists suggested nomenclatures and experimental guidelines for the macrophage activation profiles well-established by then [@Murray2014]. However, the recent abundance of genomic data has challenged the classical protein-level techniques used to sort macrophage subsets and therefore novel classifications emerged. In the same year that Murray's paper was published, a multi-center work attributed a much higher heterogeneity to macrophages through machine learning algorithms applied to single-cell transcriptome analysis [@Xue2014]. 
  
  Assessing the transcriptomes from almost 300 _in-vitro_ stimulated human macrophages, Xue and colleagues used weighted gene co-expression network analysis (WGCNA) to identify 49 co-expression modules, each of which ranging from less than 30 to over 800 distinct genes of size [@Xue2014]. Based on Pearson correlation, WGCNA defines gene clusters, known as _transcriptional modules_, which present specific co-expression patterns across each treatment condition [@Langfelder2008]. As an example, these modules can then be used to visualize the comprehensiveness of the M1 versus M2 model. As noted by the authors, stimuli not M1- or M2-associated showed prominent patterns consistent with a rather dynamic spectrum model of cell activation.
  
  In order to achieve greater depth of macrophage phenotypes characterization, in this study the 49 transcriptional modules produced by Xue and colleagues were used as relevant gene sets for further analyses. The Figure 2 shows the distribution of number of genes across the different modules.
  
![Figure 2 - Gene modules distribution.](Development_files/figure-docx/Figure2-1.png)

  As reproducibility of gene signatures discovery is challenging, here we also employ assessment of animal models data so that between-species reproducible genomic patterns - presumably more robust - can enrich integrative analysis. 
  
# Objectives

  Integrative genomic analysis is an interdisciplinary approach that arises from health sciences, engineering, biostatistics, computer sciences, and molecular biology advances. This study is mainly focused on the characterization of macrophage gene expression patterns within the context of Idiopathic Pulmonary Fibrosis, as well as the understanding of cellular subpopulations behavior at the transcriptomics level. As a general objective, we pursue the identification of genomic markers correlated with histopathological kinetics of IPF. Specific objectives are listed below.
  
  ** Characterize the temporal profile of gene signatures derived from macrophage subpopulations in animal models of IPF;
  
  ** Build numerical factor kinetically correlated with the profiles identified in the previous item;
  
  ** Assess the previously built numerical factor in gene expression datasets from IPF patients.
  

# Materials and Methods

  All analyses were performed using R software (3.4.3) and CRAN or Bioconductor packages - Table 1. Complex file parsers were built with python (3.6 or later). Parametric differences were assessed using linear and generalized linear models, t tests, and Turkey HSD test. False Discovery Rate was controlled for multiple comparisons using Benjamini-Hochberg procedure at 5% level. Non-parametric differences were assessed using Wilcoxon-Mann-Whitney test.

__BOTAR TABELA NA MAO - DEVEL_FILES/FIGS/RPACKS.TSV__
  
  [@DePianto2015; @Kabacoff2015]
  
# References

