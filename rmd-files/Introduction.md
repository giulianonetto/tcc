---
title: "Introduction"
bibliography: config/library.bib
csl: config/abnt-ufrgs-initials.csl
output: 
  word_document:
    reference_docx: config/template.docx
    keep_md: true
---



  Idiopathic Pulmonary Fibrosis (IPF) is a chronic, progressive, irreversible lung disease. After diagnosis, the interstitial condition commonly presents 3-5 years of life expectancy if untreated [@Wolters2018]. Alveolar damage is characterized by dilatation of the bronchi, tissue remodeling and parenchymal fibrosis which seriously impair gas exchange. The first time the current name was used it referred to radiography tests suggestive of pulmonary fibrosis of unknown etiology, although the disease had been recognized over one hundred years before - named cirrhosis of the lung at the time [@Robbins1948, @Wolters2018]. Over three decades after the nomenclature was first published, in 1976 it gained widespread use after a review article [@Wolters2018].
  
  Currently, radiographic and histopathological patterns of usual interstitial pneumonia (UIP) with apparently no secondary causes form the basis for IPF definition [@Richeldi2017]. The disease presents sporadic and familial forms. From the edges of the lungs - base and periphery -, it spreads all over the pulmonary tissue causing dry cough, fatigue and dyspnea. The latter is nearly universal in the history of IPF patients and may progress over a period of years, while the first two may be absent in the early stages. Universal findings also include low diffusion capacity of the lung for carbon monoxide (DLCO) and Bilateral Velcro-like crackles. The chest radiograph may present nonspecific changes or bilateral basal reticular abnormalities [@Lederer2018]. The difficulty of the diagnosis is illustrated by the fact that clinicians often mistake the presence of dyspnea as indicator of heart failure or chronic obstructive pulmonary disease (COPD), failing to consider interstitial lung disease, which delays IPF detection significantly.
  
  Although its cause is not clear, there is currently a recognized increase in IPF prevalence worldwide [@Wolters2018]. As a disease of aging, this may be due to population increasing phenomena, but also to recent improvements in disease recognition [@Lederer2018]. Unusual before the 50 years of age, IPF prevalence almost doubles for every decade of life thereafter [@Wolters2018]. In North America and Europe, the incidence of IPF ranges from 3 to 9 cases per 100000 person-years, while South America and East Asia show less than 4 cases per 100000 person-years [@Hutchinson2015]. Assuming these numbers as conservative, a recent Brazilian study tried to calculate more precise estimates for the local reality. Using data from the 2010 Brazilian National Census and rates reported by previous studies, the authors suggested annual incidence of IPF between 6.841 and 9.997 cases per 100000 people, whereas the prevalence was estimated at a range of 13.9-18.3 cases per 100000 people [@Baddini-Martinez2015]. In terms of mortality, another study estimated 1.2 deaths per 100000 people in 2010, although this is certainly an underestimation as the authors limited their analysis to data from the Information Technology Department of the Brazilian Unified Health Care System (DATASUS), which does not reflect private medicine practices [@Rufino2013]. It is clear, however, that Brazil's data does not oppose the world tendency of IPF prevalence increase.
  
  The number of disease cases has risen along with the number of identified risk factors. Regarding hospitalization, over three quarters of the cases are due to respiratory events, with acute exacerbations as the main cause [@Brown2015; @Song2011]. In-hospital mortality rate has been reported to reach 50 %, with five-year survival from initial diagnosis lower than 20 % [@Song2011]. In such a complex scenario, multidimensional indexes that include sex, age and physiological abnormalities may be useful to predict mortality [@Richeldi2017]. Risk factors also include environmental exposures to dust and air pollution, smoking, chronic viral infections ( _e.g._ Epsteinâ€“Barr virus, cytomegalovirus and Kaposi sarcoma-associated herpesvirus) and other comorbidities. Of note, one third of inherent individual risk of IPF have been attributed to genetic variants. Mutations in genes associated with telomere length - such as TERT, TERC, PARN, and RTEL1 - are related to higher higher risk of IPF. The same holds true for genes responsible for cell adhesion, integrity, and mechanotransduction ( _e.g._ DSP, AKAP13, CTNNA, and DPP9) [@Lederer2018].
  
  Mucin 5B overexpression in small-airway epithelial cells is a universal finding in patients with IPF, which has led to the hypothesis that impaired mucociliary clearance may be linked to changes in microbiome and innate immune responses that promote IPF [@Molyneaux2017; @Lederer2018]. Although the gene expression pattern appears to be genotype-independent, single-nucleotide polymorphisms in the MUC5B gene are notable risk factors for IPF, even though - paradoxically - they may also predict slower disease progression [@Peljto2015]. Host-microbiome interactions are also highlighted by the central role of macrophages in lung fibrosis development along with the finding that IPF risk is also increased by mutations in the TOLLIP gene, which encodes a protein associated with toll-like receptor family pathways [@Lederer2018]. Lung of patients typically present higher bacterial loads, differences in microbiota composition and diversity, and even increases in potentially pathogenic bacteria ( _e.g._ _Staphylococcus_ spp. and _Streptococcus_ spp.). Finally, epigenetic reprogramming has been associated with pathogenesis of IPF [@Richeldi2017]. Upregulation of lung development genes, trans-regulatory methylation marks near transcription factors, and potentially pathogenic modifications in miRNAs have been pointed as complex reprogramming processes often associated with pro-fibrotic pathways. 
  
  Overall, it is well accepted that IPF arises from recurrent, subclinical epithelial injury, especially in genetically-predisposed individuals with accelerated epithelial aging [@Lederer2018]. In such patients, the repetitive alveolar damage can induce pro-fibrotic epigenetic reprogramming, persistent cell senescence, production of pro-fibrotic molecules as well as activation of mesenchymal cells [@Richeldi2017]. Recent studies, however, have been suggesting that the trigger for lung fibrosis might not be strictly related to exogenous aggression, which is yet to be further investigated [@Kulkarni2016; @Naikawadi2016]. Still, altered migration, proliferation and mixed activation profiles of epithelial cells, especially alveolar epithelial type 2 cells, are a hallmark of IPF [@Richeldi2017]. These and other pathological discoveries will be critical for early diagnosis and treatment development.
  
  Currently, diagnosis of IPF is mainly focused on high-resolution computed tomographic (CT) imaging after identification of history and physical examination that are suggestive of interstitial lung disease [@Lederer2018]. Once the suspicion is confirmed, further physical examination is performed to rule out related disorders such as chronic hypersensitivity pneumonitis and connective-tissue disease, as well as autoimmune conditions. Antinuclear antibodies, rheumatoid factor, antibodies against cyclic citrullinated peptides, Scl-70, Ro, La, U1-RNP, Jo-1 and other immunological tests comprise the serological examination routine, even though the presence of these biomarkers may not be enough to confirm IPF absence [@Lederer2018]. Often, lung biopsy is not performed in face of usual interstitial pneumonia (UIP) in high-resolution CT associated with suitable history, these being enough for IPF diagnosis. However, obvious CT patterns are not always present and invasive methodologies are needed. If histologic UIP is present, IPF diagnosis is confirmed. Otherwise, multidisciplinary discussions are encouraged as means of increasing diagnostics and prognosis assessment [@Lederer2018].
  
  Finally, in terms of pharmacotherapy, IPF management has been through recent international standardization. In 2015 the American Thoracic Society, European Respiratory Society, Japanese Respiratory Society and Latin American Thoracic Association (ATS/ERS/JRS/ALAT) released international IPF therapy guidelines, updating a previous version from 2011 [@Raghu2015]. The guidelines strongly favored the recommendation for use of Pirfenidone and Nintedanib [@Richeldi2017]. While the latter is a tyrosine kinase inhibitor taken twice daily, the former acts on various pathways, inhibiting TGF-b production and downstream signaling, among other effects [@Lederer2018]. In addition to the need of three daily doses, Pirfenidone may cause anorexia, nausea and photosensivity, and may have its blood levels increased by CYP 1A2 inhibitors. Nintedanib causes diarrhea, risk of bleeding and arterial thrombosis, and a low risk of gastrointestinal perforation. Both treatments require liver-function monitoring and have similar efficacy profiles - reducing forced vital capacity decline rate by nearly half, clearly insufficient for stopping disease progression. 
  
# Immunological background of IPF
  
  Despite the limited capacity of recapitulating IPF, animal models have been useful for identifying related pathways relevant for drug discovery and diagnostic tools development. Using these techniques, several immune-related molecules have been implicated to IPF, including transforming growth factor beta (TGF-b), connective-tissue growth factor (CTGF), tumor necrosis factor (TNF), fibroblast growth factor 2, platelet-derived growth factor, several matrix metalloproteinases and chemokines [@Lederer2018; @Richeldi2017]. The fibrotic process itself has its own singularities as well. A wide range of interleukins and other immunologically active mediators have been proposed as critical for fibrotic processes. Among others, these include IL-33, IL-17A, IL-25, TSLP, and IL-13 [@Gurczynski2017; Li2014; @Camelo2017; @Hams2015]. Regarding immune cell populations, macrophages have been shown to play central roles in pulmonary fibrosis and the elucidation of their biological dynamics is an active area of current research effort [@Venosa2016; @Lee2018; @Kurowska-Stolarska2009; @Misharin2013; @Wynn2010; @Misharin2017].
  
  Subpopulations of macrophages and monocytes-derived cells are recognized as centrally active in pulmonary immunological processes [@Martinez2014; @Syrbu1996; @Braga2015; @Misharin2013; @Hussell2014]. Indeed, these cells can be source of pathophysiological information throughout disease progression for two main reasons. Firstly, they act as sentinels for foreign aggression, which assures detectable variance in animal models from the very beginning of the induced lesion and inflammation [@Martinez2014]. Secondly, as anti-inflammatory and pro-fibrotic mechanisms progress, the above-mentioned cells are also fundamentally involved in both the regulatory functions and the fibrosis promotion [@Luzina2015; @Camelo2017]. Most recruited monocytes differentiate into macrophages upon tissue arrival. These cells respond differently across distinct phases of pulmonary immunological activity so that understanding their dynamics throughout the course of lung aggression is critical [@Wynn2010]. Although not limited to a dichotomous model, M1- and M2-like cells typically promote and modulate these mechanisms, and their deep phenotypic profiling is crucial for the understanding of IPF and other fibrosis-related conditions.
  
## Macrophages and fibrosis development
  
  The definition of common macrophage subpopulations is currently under scientific scrutiny and revision [@Martinez2014]. Traditionally, macrophages were thought to be divisible into two groups, depending on the activation stimuli to which they are exposed [@Abbas2017]. Classical activation is triggered by exposure to microbial toll-like receptor ligands such as lipopolysaccharide (LPS) and cytokines commonly released by T helper 1 cells (TH1), especially Interferon-g (IFN-g). These signals enhance the antimicrobial and tumoricidal properties of what is then named M1 macrophage. M1 cells promote potentially harmful inflammation, but are crucial to fight, for instance, viral infections and cancer [@Alfano2013; @Dale2013; @Ginhoux2016]. Alternative activation occurs when macrophages are exposed to cytokines characteristic of T helper 2 cells (TH2), notably IL-4 and IL-13, and the then called M2 macrophages inhibit inflammation and promote tissue repair and fibrosis [@Delves2017]. The M1 vs M2 paradigm has been used worldwide and certainly contributed to the advancement of modern immunology. The M1 or M2 responses were referred to as analogous to the TH1 and TH2 responses, and the preferential differentiation of a group of cells in a given environment into one of the phenotypes is termed as "macrophage polarization" [@Ginhoux2016]. 
  
  However, as these cellular subtypes were first defined with controlled _in vitro_ experiments, more complex phenotypic experimental characterizations started to give birth to the model questioning. Subdivisions of M2 macrophages arose from the observation of subtly distinct phenotypes, depending on the anti-inflammatory stimulus used. M2a phenotype is traditionally triggered by IL-4 and IL-13; M2b phenotype is induced by IL-10 exposure; and M2c cells are generated with a combination of immune complexes and LPS. Flow cytometry analyses now include several markers for each phenotype and their subdivisions, but these are often conflicting between studies [@Tarique2015; @Venosa2016; @Misharin2013]. It is now clear that many homeostatic and pathological situations do not support M1 or M2 phenotypes dichotomy, and that in many cases these cells present high phenotypic plasticity [@Ginhoux2016]. Macrophage activation is influenced by their ontogeny ( _i.e._ if they derive from yolk sac, as the microglia, fetal liver monocytes, as lung macrophages and Kupffer cells, from both, as Langerhans cells, or if they are replaced with adult bone marrow monocytes, as in the gut, heart an dermal macrophages). Tissue-specific signals also drive macrophage activation both in homeostasis and disease and, importantly, the same stress signals with the same kinetics result in differentially programmed macrophages if these have been exposed to different microenvironments or previous stimuli. Taken together, these recent advances lead the understanding of macrophage biology to a multidimensional model of activation, with major microenvironment particularities and transcriptional programs significantly variable across human and mouse normal tissues and pathological conditions.  
  
  Faced with the need for standardization, a group of macrophage biology researchers suggested a reviewed nomenclature and experimental guidelines for subpopulation studies [@Murray2014]. The proposal was based on three principles: "source of macrophages, definition of the activators, and a consensus collection of markers to describe macrophage activation". As it remains a challenge to define macrophage phenotypes that describe accurately the cellular function across time and environmental conditions, the authors proposed nomenclature designation based on the stimuli to which the cells are exposed, for _in vitro_ studies. For instance, traditional M1 macrophages would now be named M(LPS) or M(IFN-g) cells, while M2 would be further divided into M(IL-4), M(IL-4+IL-13), M(IL-10), etc. For _in vivo_ studies, the cell names would explicitly declare their multiple markers rather then forcing a fit into M1 or M2 spectra. Many confusions are avoided by this approach. For instance, the expression of Arginase-1 has been used to describe M2 - or M(IL-4) - macrophages, while it is well known that the enzyme is also expressed by M1 spectrum cells as well as resident macrophages [@Murray2014]. Additionally, the authors suggest terms to be avoided as these may further confuse classification: "regulatory macrophages" has been used to refer to M2-like cells, despite the fact that all macrophages show regulatory functionalities at some point and even within the M2 spectrum the regulatory functions are considerably heterogeneous. Although their nomenclature standards have been extensively encouraged, macrophages are still presented as M1-like or M2-like in many occasions, especially when accurate classification is not achieved [@Italiani2014; @Venosa2016; @Malaviya2016; @Becker2015a; @Wermuth2015; @Murray2017]. In such a controversial scenario, novel approaches are currently needed to further improve macrophage classification.
  
## Novel approaches in macrophage biology research
  
  One of the promising techniques applied to macrophage study is high-throughput gene expression analysis. High-throughput technologies have been available for almost two decades now, and these have deeply challenged our current understanding of macrophage biology [@Stables2011; @Kidd2014; @Pevsner2015]. A remarkable work from Xue and colleagues (2014) is an outstanding example of these advances. Using diverse _in vitro_ stimuli, the authors performed single-cell RNA sequencing on almost 300 macrophages [@Xue2014]. Weighted Correlation Network Analysis identified 49 stimulus-specific gene modules that could be used as gene sets for enrichment assessment on data from patients and animal models. This approach deeply extended M1- versus M2-paradigm towards a "spectrum model of human macrophage activation" and was able to identify a refined, activation-independent core signature for human and murine macrophages. In fact, module analysis has been widely used to investigate transcriptional profiles of immunological processes. First designed using k-means clustering algorithm for microarray data, it identifies groups of genes that are coordinately expressed in a given dataset while supporting systems-scale analysis for translational research [@Chaussabel2008]. Currently, this type of procedure is performed by widely used software which implement diverse set of machine learning algorithms [@Langfelder2008]. Additionally, it has been adapted to RNA sequencing and single-cell RNA sequencing data. The wide range of algorithms currently used has been comprehensively reviewed elsewhere [@Saelens2018].
  
  Apart from transcriptome studies, proteomic data analysis has yielded promising results as well [@Court2017]. Despite the difficulty of validating direct relationships between gene and protein expression patterns, the one agreement is that M1 versus M2 model is not enough to explain macrophage polarization repertoire [@Martinez2014; @Tarasova2016a; @Kamal2018]. Nevertheless, as Next Generation Sequencing became broadly available at relatively low costs, proteome research is still to match high-throughput transcriptomic techniques in terms of scaling and data generation capacity. Overall, multi-omics approaches start to gradually emerge as the amount of data currently being generated by far exceeds the data analysis resources available for the scientific community.
  
# Bioinformatics and Functional Genomics
  
  According to Jonathan Pevsner (2015), "functional genomics is the genome-wide study of the function of the DNA (including genes and nongenic elements) as well as the nucleic acid and protein products encoded by DNA" [@Pevsner2015]. The author also states that functional genomics relies primarily on the use of high-throughput technologies, such as Next Generation Sequencing (NGS) and microarray. More traditional techniques such as real-time polymerase chain reaction are used as means of validation. Finally, Pevsner emphasizes that functional genomics plays a fundamental role in solving one of the ultimate problems in modern biology: understanding the relationship between genotype and phenotype [@Pevsner2015]. 
  
  It is not surprising that these approaches have been broadly applied to macrophage biology studies [@Fonseca2017]. The massive amount of data generated, though, represents a challenge for researchers. This scenario has led to the advance of the bioinformatics field, which stands at the interface between molecular biology and computer science. Briefly, bioinformatics seeks the analysis of molecular sequences - which can derive from DNA, RNA, or proteins - to answer a broad range of biological questions. Genomics is dedicated to the analysis of DNA sequences of organisms - the genomes -, while transcriptomics analyzes the transcriptome and proteomics, the proteome - and so forth. Going further, Functional Genomics takes advantage of genome-wide assays to understand gene, transcript, and protein functions. Although there are obvious overlaps among the terms, a first perspective of the big picture of bioinformatics suggested by Pevsner is the cell itself: the central dogma of molecular biology states that the relationships between DNA, RNA and proteins ultimately generate cellular phenotype. In genomics, the central dogma is translated into the relationships between the genome, transcriptome and proteome. This approach greatly enhances the complexity of cellular phenotype modeling, and hence computational methods are needed [@Pevsner2015]. Still, strict definition of these and related terms is often controversial and beyond the scope of this work.
  
## Bioinformatics Development
  
  The development of bioinformatics software is probably one of the most exciting areas of recent scientific advances. A popular approach is web-development for scientific computing. Open, web-available tools such as Basic Local Alignment Search Tool (BLAST) at National Center for Biotechnology Information (NCBI) make it possible for researchers with no programming experience to perform complex bioinformatics analyses [@Quereda2016]. The paper that introduced BLAST in 1990 counts over 74000 citations as of November, 2018 - similar to the citation numbers from Cesar Victoria, one of the Brazilian scientists with the highest citation counts at Google Scholar currently [@Victoria2018]. However, programming abilities are a restrictive must for those seeking to further customize their analyses or to develop their own algorithms. Although several academic majors take advantage of bioinformatics development, from biology to health sciences, programming skills are often neglected. In Brazil, few are the undergraduate programs that include bioinformatics as a discipline and even fewer are the specialized and well developed bioinformatics graduate programs. This reality is now trending to change as computational biology applications gain major highlights in media and academic routine.
  
  Regarding programming languages, one is particularly outstanding in the field of Functional Genomics. The R programming language is both a language and an environment for statistical computing and graphics, similar to the S language previously developed by John Chambers and colleagues at Bell Laboratories [@Rproject2018]. Like S, in R one can program their own functions and extend base functionality through the use of packages - which are just R code with certain functionalities validated and encapsulated. Also, it is possible to link C and C++ code to these packages so that computationally-intensive tasks can be performed. The idea of programming "environment" comes from the production a coherent and well-planned framework in which statistical computing can be run and developed. This can contrast with other programming languages such as python, which can be applied to statistics and data analysis in spite of its broader range of applications. Python is another very popular data science language with extensive machine learning algorithm development, although its reach in the field of functional genomics may not be as extensive as in the case of R.
  
  The success of R within bioinformatics field has a particular reason. In 2001, a group of researchers, bioinformaticians, statisticians, and data scientists released Bioconductor, an open-source, open development software project dedicated to the analysis of high-throughput genomic data [@Gentleman2004]. To date, the package repository contains over 1600 software packages, which undergo continuous automated testing in addition to formal initial review [@Huber2015]. Bioconductor also supports the rapid development of standard workflows combining highly complex data structures and statistical inference tools, regression, network analysis, machine learning and data visualization, which is especially important for reproducible research. It is deeply documented at three levels: whole workflows combining multiple tools, packages vignettes providing the narrative for the package usage with code and data analysis examples, and manual pages that serve as reference for detailed descriptions of all inputs and outputs for the packages functions. With enough experience, users can become developers and share their work with others through the repository. The choice of R language is justified by its high-level statistical and graphical utilities, which yields rapid prototyping creativity, flexibility and reproducibility unmatched by web-based tools software and general-purpose languages [@Huber2015]. The whole Bioconductor structure and development culture are focused on reproducible research and data analysis, which translate into good practices for documentation and software development that well enforced by the users and developers community.
  
## Microarray data analysis using Bioconductor

  DNA Microarray is a genome-wide gene expression measurement technique that emerged by 2000, although it was first developed in the previous decade at Stanford University and National Institute of Health (NIH) [@Pevsner2015]. It has been one of the most widely used tool for genomic studies worldwide [@Sinha2014]. On the surface of a solid support, several nanograms of DNA are immobilized in a grid-like array. The RNA extracted from biological samples is usually converted to complementary DNA (cDNA) - or cRNA, depending on the platform -, labeled with fluorescence, and selectively hybridized to the array. Each transcript should have a corresponding nucleic acid molecule to which hybridize, although often more than one probe maps to the same gene. Either for technical reasons, or because a particular gene may have more undergo alternative splicing and thus different expression values are expected, _probesets_ are particularly common on the Affymetrix platform [@Liu2003]. Once the microarray is washed, image analysis quantifies the fluorescence signals, and the spot intensities are assumed to correlate with the initial quantity of sample mRNA. The amount of starting material varies across technologies, but for many cases about 1-3 ug (micrograms) of total RNA is needed and the yielded hybridization material usually consists of 5 ng of cDNA. 
  
  Data analysis seeks the identification of differentially expressed genes and broad patterns of gen expression [@Pevsner2015]. The Minimum Information About a Microarray Experiment (MIAME) provides good practices for experiment description, including experimental and microarray design, sample preparation, hybridization procedures, image analysis, and normalization controls. Microarray data is public available mainly through ArrayExpress and Gene Expression Omnibus from the European Bioinformatics Institute (EBI )and NCBI, respectively. Following MIAME is a requirement for using these databases to share your own data. Once microarray data is acquired, it must be properly normalized, undergo inferential statistics ( _e.g._ t-tests, analysis of variance), exploratory analysis ( _e.g._ unsupervised learning as clustering, dimensionality reduction), and classification ( _e.g._ supervised analyses as linear discriminants, support vector machines). These procedures ultimately lead to biological confirmation, which may be performed by non-high-throughput technologies such a RT-PCR. As all steps require complex calculations and extensive computing, many software options are available at Bioconductor, including platform-specific workflows and high-dimensional statistics tools.
  
  Microarray data distribution is often non-parametric and thus data normalization is essential for sample and experiment comparisons [@Quackenbush2002]. This is because of differences in the labeling efficiency, the amount of starting material, cDNA quality, signal detection, and so forth. Many techniques have been developed to solve this issue. Variance Stabilization and Normalization (VSN) assumes the variance for a specific probe mainly depends on its mean expression level and uses a linear transformation procedure to keep variance approximately constant [@Huber2002]. Such a technique is broadly applied and is implemented in R through the vsn package - available from Bioconductor.
  
  In 2003, Rafael Irizarry introduced the Robust Multiarray Analysis as a method of background correction, quantile normalization, and probeset summarization of probe intensities from Affymetrix platform raw data [@Irizarry2003]. As a nonparametric approach, quantile normalition makes no assumptions on the expression distributions. For each array, each probe expression measurement is assigned to a quantile. Normalization results from converting original probeset values to their corresponding quantile's values. Using a convolution model, RMA is able to distinguish true probeset signal from noise. A improved version, GCRMA, increases RMA's accuracy by adjusting nonspecific hybridization using sequence information [@Pevsner2015]. After comparing over 30 algorithms for Affymetrix microarray data, Irizarry and colleagues demonstrated the leading capacity of RMA and GCRMA procedures [@Irizarry2006]. Both methods can be easily applied through the affy package [@Gautier2004].
  
  Another issue with high-throughput data analysis is the amount of statistical tests. When measuring differential gene expression, one may perform over 20000 t-tests or Mann-Whitney and Wilcoxon tests, for instance - one for each probeset or gene. In this scenario, with a p-value threshold of 0.05, one can expect around 1000 false-positive rejections of the null hypothesis - an unacceptably high rate of type I error. In order to control for these, one must consider correction of p-values.
  
  The Bonferroni procedure is used to control the Family Wide Error Rate, which can be defined as the probability of making at least one type I error among all tests [@Irizarry2015]. It is considered a rather conservative correction as it sets a new significance cutoff by dividing our previous one - 0.05 - by the number of statistical tests performed. Thus, one must not expect high statistical power with a resulting $\alpha {= 0.0000025}$. A more common approach is to control the False Discovery Rate, which is the proportion of false calls among one's positive results  - amount of errors over the number of rejections of the null. In gene expression experiments, $FDR {= 0.05}$ means that 5% of transcripts that were called significant are actually not differentially expressed [@Pevsner2015]. For a dataset with 20000 genes and 100 signifcantly induced or repressed genes, such an FDR value would yield only 5 type I errors. The Benjamini-Hochberg procedure, easily applied in R, ranks p-values and assures an FDR below a given value of the analyst choice - typically 0.05 [@Irizarry2015].
  
  A final microarray data analysis deserves consideration regarding the detection of differentially expressed genes. In R, this task is commonly performed using linear models. The most common Bioconductor package for this purpose is limma [@Ritchie2015]. It computes ordinary t-statistics for linear model fits to all genes and then uses Bayesian modeling to moderate residual variance. As limma has been available for almost two decades now, novel packages became publicly available trying to extend and improve limma capabilities. Alternative approaches emerged for time-course gene expression analysis as it is particularly complex. MaSigPro is another R package which uses two regression steps for this specific scenario. First, it fits a global regression model - typically polynomial - and, sencondly, it performs stepwise regression to observe group differences and statistically significant longituginal profiles of gene expression [@Conesa2006]. Finally, longitudinal gene set analysis software has been developed by Hejblum and colleagues [@Hejblum2015]. The TcGSA package, available from the Comprehensive R Archive Network (CRAN), extends limma and MaSigPro techniques through random effects modeling with maximum likelihood estimates. It is capable of handling unbalanced repeated measures of gene expression and takes into account potential heterogeneity of expression profile within gene sets. The identification of differences in longitudinal expression patterns across factors of interest is thereby made possible.
  
  
# References

